<!DOCTYPE html>
<html>
<head>
    <!-- [[! Document Settings ]] -->
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />

    <!-- [[! Page Meta ]] -->
    <title>Stanford Machine Learning Week 10 review</title>
    <meta name="description" content="7 a.m. in the morning - The coding story begins here." />

    <meta name="HandheldFriendly" content="True" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />

    <link rel="shortcut icon" href="/assets/images/favicon.ico" >

    <!-- [[! Styles'n'Scripts ]] -->
    <link rel="stylesheet" type="text/css" href="/assets/css/screen.css" />
    <link rel="stylesheet" type="text/css"
          href="//fonts.googleapis.com/css?family=Merriweather:300,700,700italic,300italic|Open+Sans:700,400" />
    <link rel="stylesheet" type="text/css" href="/assets/css/syntax.css" />

    <!-- [[! highlight.js ]] -->
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.3.0/styles/default.min.css">
    <style>.hljs { background: none; }</style>
    <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.3.0/highlight.min.js"></script>
    <script>hljs.initHighlightingOnLoad();</script>

    <!-- [[! Ghost outputs important style and meta data with this tag ]] -->
        <link rel="canonical" href="/" />
    <meta name="referrer" content="origin" />
    <link rel="next" href="/page2/" />

    <meta property="og:site_name" content="7 a.m. in the morning" />
    <meta property="og:type" content="website" />
    <meta property="og:title" content="7 a.m. in the morning" />
    <meta property="og:description" content="The coding story begins here." />
    <meta property="og:url" content="/" />
    <meta property="og:image" content="/assets/images/cover-write.jpg" />

    <meta name="twitter:card" content="summary_large_image" />
    <meta name="twitter:title" content="7 a.m. in the morning" />
    <meta name="twitter:description" content="The coding story begins here." />
    <meta name="twitter:url" content="/" />
    <meta name="twitter:image:src" content="/assets/images/cover-write.jpg" />

    <script type="application/ld+json">
{
    "@context": "http://schema.org",
    "@type": "Website",
    "publisher": "Finding The Way Home",
    "url": "/",
    "image": "/assets/images/cover-write.jpg",
    "description": "The coding story begins here."
}
    </script>

    <meta name="generator" content="Jekyll 3.0.0" />
    <link rel="alternate" type="application/rss+xml" title="7 a.m. in the morning" href="/feed.xml" />


</head>
<body class="home-template nav-closed">

    <div class="nav">
    <h3 class="nav-title">Menu</h3>
    <a href="#" class="nav-close">
        <span class="hidden">Close</span>
    </a>
    <ul>
        <li class="nav-home " role="presentation"><a href="/">Home</a></li>
        <li class="nav-algorithm " role="presentation"><a href="/tag/algorithm">Algorithm</a></li>
        <li class="nav-java " role="presentation"><a href="/tag/java">Java</a></li>
        <li class="nav-python " role="presentation"><a href="/tag/python">Python</a></li>
        <li class="nav-machine-learning " role="presentation"><a href="/tag/machine-learning">Machine Learning</a></li>
        <li class="nav-productivity " role="presentation"><a href="/tag/productivity">Productivity</a></li>
        <li class="nav-author " role="presentation"><a href="/author/kewei">Author</a></li>
        <li class="nav-about " role="presentation"><a href="/about">About</a></li>
    </ul>
    <a class="subscribe-button icon-feed" href="/feed.xml">Subscribe</a>
</div>
<span class="nav-cover"></span>


    <div class="site-wrapper">

        <!-- [[! Everything else gets inserted here ]] -->
        <!-- < default -->

<!-- The comment above "< default" means - insert everything in this file into -->
    <!-- the [body] of the default.hbs template, which contains our header/footer. -->

<!-- Everything inside the #post tags pulls data from the post -->
<!-- #post -->

<header class="main-header post-head " style="background-image: url(/assets/images/cover-s-ml-w10.png) ">
    <nav class="main-nav  overlay  clearfix">
        <a class="blog-logo" href="/"><img src="/assets/images/home.png" alt="Blog Logo" /></a>
        
            <a class="menu-button icon-menu" href="#"><span class="word">Menu</span></a>
        
    </nav>
</header>

<main class="content" role="main">

    <article class="post machine-learning">

        <header class="post-header">
            <h1 class="post-title">Stanford Machine Learning Week 10 review</h1>
            <section class="post-meta">
            <!-- <a href='/'>Kewei Shang</a> -->
            <time class="post-date" datetime="2016-07-10">10 Jul 2016</time>
                <!-- [[tags prefix=" on "]] -->
                 
                on 
                
                    
                       <a href='/tag/machine-learning'>Machine-learning</a>
                       
                
                
            </section>
        </header>

        <section class="post-content">
            
            <p>This week’s machine learning course is about training large dataset and Stochastic Gradient Descent.</p>

<h5 id="what-is-the-problem-with-learning-with-large-dataset">What is the problem with learning with large dataset?</h5>

<p>When training the parameters with a large dataset, such as 100 million training examples or even more, we may not be able to fit all training example into memory. However, we do need all the training examples to calculate partial derivatives for all the parameters. That means, for each step of gradient descent, we have to calculate the next θ value by accumulating the h(θ) - y of all the training examples. How can we deal with that if the training example is too large to fit into memory?</p>

<h5 id="three-solutions">Three solutions</h5>

<ul>
  <li>Stochastic Gradient Descent</li>
  <li>Mini-Batch Gradient Descent (may be more efficient)</li>
  <li>Map Reduce (multiple machines)</li>
</ul>

<h5 id="stochastic-gradient-descent">Stochastic Gradient Descent</h5>

<p>Each update of θ is calculated by only one training example. Stochastic gradient descent is much faster than Batch gradient descent. Each baby step -update θ values - of Batch gradient descent uses all training examples, whereas each baby step of Stochastic gradient descent uses only one training example. But one caveat here is that even though the baby steps of Stochastic gradient descent will generally move the parameters in the direction of the global minimum, but not always. In fact as you run Stochastic gradient descent it doesn’t actually converge in the same sense as Batch gradient descent does, and what it ends up doing is wandering around continuously in some region that’s close to the global minimum, but it doesn’t just get to the global minimum and stay there. In practise, it isn’t a problem though since it will be a pretty good hypothesis.</p>

<p><img src="assets/images/s-ml-w10-1.png" alt="" /></p>

<h5 id="stochastic-gradient-descent-convergence">Stochastic gradient descent convergence</h5>

<p>We can plot a learning curve to check if the our stochastic gradient descent is converging when more and more iterations. The x-axis is the number of iterations, and the y-axis is the cost function. As we can see in the top-left figure, we get a slightly better result when we use a smaller learning rate. The top-right figure shows we get a more smoothy curve when calculating the cost function every 5000 iterations instead of every 1000 iterations. The bottom-right figure shows if the learning rate is too large, the learning curve might end up diverging.</p>

<p><img src="assets/images/s-ml-w10-2.png" alt="" /></p>

<h5 id="mini-batch-gradient-descent">Mini-Batch Gradient Descent</h5>

<p>It’s just another variation of stochastic gradient descent. Instead of calculating one training example at a time, it calculates multiple (mini batch) training examples. Mini-batch gradient descent is likely to outperform Stochastic gradient descent only if you have a good vectorised implementation, paralleling your computation.</p>

<h5 id="map-reduce">Map Reduce</h5>

<p>All learning algorithms that can be expressed as a summation over the training set can apply Map Reduce in order to speed up the computation. By paralleling the computation over different computers. So whether it’s Linear Regression, Logistic Regression, or Neural Network, they can all apply map reduce. For example, if we have 400 million training examples, we can partition them into 4 computers and each computer calculates one fourth of the training examples, before another machine combines the 4 results together to calculate the partial derivative.</p>

<p><img src="assets/images/s-ml-w10-3.png" alt="" /></p>

<h5 id="what-is-online-learning">What is Online Learning?</h5>

<p>When you can continuously have streams of new training examples and you don’t want to save all the previous training examples because you constantly have new data. Then you can use Online learning. It continuously (forever) calculate the stochastic gradient descent.</p>


        </section>

        <footer class="post-footer">

            <!-- Everything inside the #author tags pulls data from the author -->
            <!-- #author-->

            
            <figure class="author-image">
                <a class="img" href="/author/kewei" style="background-image: url(/assets/images/casper.png)"><span class="hidden">'s Picture</span></a>
            </figure>
            

            <section class="author">
                <h4><a href="/author/kewei">Kewei Shang</a></h4>
                
                
                    <p> Software engineer, runner, reader</p>
                
                <div class="author-meta">
                    <span class="author-location icon-location"> Paris, France</span> 
                    <span class="author-link icon-link"><a href="http://github.com/keweishang/"> github.com/keweishang/</a></span> 
                </div>
            </section>

            <!-- /author  -->

            <section class="share">
                <h4>Share this post</h4>
                <a class="icon-twitter" href="http://twitter.com/share?text=Stanford Machine Learning Week 10 review&amp;url=http://github.com/keweishang/stanford-ml-w10"
                    onclick="window.open(this.href, 'twitter-share', 'width=550,height=235');return false;">
                    <span class="hidden">Twitter</span>
                </a>
                <a class="icon-facebook" href="https://www.facebook.com/sharer/sharer.php?u=http://github.com/keweishang/stanford-ml-w10"
                    onclick="window.open(this.href, 'facebook-share','width=580,height=296');return false;">
                    <span class="hidden">Facebook</span>
                </a>
                <a class="icon-google-plus" href="https://plus.google.com/share?url=http://github.com/keweishang/stanford-ml-w10"
                   onclick="window.open(this.href, 'google-plus-share', 'width=490,height=530');return false;">
                    <span class="hidden">Google+</span>
                </a>
            </section>
            
            <!-- Add Disqus Comments -->
            
            
        </footer>

    </article>

</main>

<aside class="read-next">

    <!-- [[! next_post ]] -->
    
        <a class="read-next-story " style="background-image: url(/assets/images/cover-s-ml-w11.jpg)" href="/stanford-ml-wf-copy">
            <section class="post">
                <h2>Stanford Machine Learning Final Week Review! Congratulations!</h2>
                <p>This week's machine learning course is about Machine Learning Pipeline. It's a system with many...</p>
            </section>
        </a>
    
    <!-- [[! /next_post ]] -->
    <!-- [[! prev_post ]] -->
    
        <a class="read-next-story prev " style="background-image: url(/assets/images/cover-s-ml-w9.jpg)" href="/stanford-ml-w9">
            <section class="post">
                <h2>Stanford Machine Learning Week 9 review</h2>
                <p>This week’s machine learning course is about Anomaly Detection and Recommender Systems. What is Anomaly...</p>
            </section>
        </a>
    
    <!-- [[! /prev_post ]] -->
</aside>

<!-- /post -->


        <footer class="site-footer clearfix">
          <section class="copyright"><a href="/">7 a.m. in the morning</a> &copy; 2016</section>
        </footer>
    </div>
    <!-- [[! Ghost outputs important scripts and data with this tag ]] -->
    <script type="text/javascript" src="https://code.jquery.com/jquery-1.11.3.min.js"></script>
    <!-- [[! The main JavaScript file for Casper ]] -->
    <script type="text/javascript" src="/assets/js/jquery.fitvids.js"></script>
    <script type="text/javascript" src="/assets/js/index.js"></script>

    <!-- Add Google Analytics  -->
        <!-- Google Analytics Tracking code -->
     <script>
	    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

	    ga('create', 'UA-69281367-1', 'auto');
	    ga('send', 'pageview');

     </script>   
</body>
</html>
